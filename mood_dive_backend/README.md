# Mood Dive Shopping Assistant Backend

ë¡œì»¬ Llama (Ollama)ë¥¼ ì‚¬ìš©í•œ ì‡¼í•‘ ì–´ì‹œìŠ¤í„´íŠ¸ ë°±ì—”ë“œ ì„œë²„

## í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

### 1. Ollama ì„¤ì¹˜

```bash
# macOS
brew install ollama

# ë˜ëŠ” ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ìš´ë¡œë“œ
# https://ollama.ai/download
```

### 2. Llama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# Llama 3.2 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ê¶Œì¥)
ollama pull llama3.2

# ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸
# ollama pull llama2
# ollama pull llama3.1
```

### 3. Python í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ì„ íƒì‚¬í•­)
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate  # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

## ì‹¤í–‰ ë°©ë²•

### 1. Ollama ì„œë²„ ì‹œì‘

```bash
# ë°±ê·¸ë¼ìš´ë“œì—ì„œ Ollama ì‹¤í–‰
ollama serve
```

### 2. FastAPI ì„œë²„ ì‹œì‘

```bash
# ë°±ì—”ë“œ ë””ë ‰í† ë¦¬ì—ì„œ
python main.py
```

ì„œë²„ê°€ `http://localhost:8000`ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.

### 3. ì„œë²„ ìƒíƒœ í™•ì¸

```bash
# ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°
open http://localhost:8000

# ë˜ëŠ” curlë¡œ í™•ì¸
curl http://localhost:8000/health
```

## API ì—”ë“œí¬ì¸íŠ¸

### GET /
ì„œë²„ ì •ë³´ í™•ì¸

### GET /health
Ollama ì—°ê²° ìƒíƒœ í™•ì¸

### POST /chat
ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡

**Request Body:**
```json
{
  "message": "ìºì£¼ì–¼í•œ ì²­ë°”ì§€ ì¶”ì²œí•´ì¤˜",
  "style_context": "ë°ì¼ë¦¬",
  "age_group": "20s"
}
```

**Response:**
```json
{
  "response": "ì™„ì „ ì¢‹ì€ ì„ íƒì´ì—ìš”! ğŸ˜Š ë°ì¼ë¦¬ë£©ìœ¼ë¡œ ì²­ë°”ì§€ëŠ” í•„ìˆ˜ì£ ..."
}
```

### POST /greeting
ì´ˆê¸° ì¸ì‚¬ë§ ìƒì„±

**Request Body:**
```json
{
  "style_context": "ëª¨ë˜",
  "age_group": "30s"
}
```

## ì—°ë ¹ëŒ€ë³„ íŠ¹ì§•

- **20s**: íŠ¸ë Œë””í•˜ê³  ìºì£¼ì–¼, ì´ëª¨ì§€ ì‚¬ìš©, ìµœì‹  íŠ¸ë Œë“œ
- **30s**: ì‹¤ìš©ì ì´ê³  ì „ë¬¸ì , ê°€ì„±ë¹„ì™€ í’ˆì§ˆ ê· í˜•
- **40s**: ì‹ ë¢°ê° ìˆê³  ì •ì¤‘, í’ˆì§ˆê³¼ ë¸Œëœë“œ ì¤‘ì‹œ
- **50s**: ì¹œì ˆí•˜ê³  ìì„¸í•œ ì„¤ëª…, í´ë˜ì‹í•˜ê³  ê²€ì¦ëœ ì œí’ˆ

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Ollama ì—°ê²° ì‹¤íŒ¨
```bash
# Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
ps aux | grep ollama

# Ollama ì¬ì‹œì‘
killall ollama
ollama serve
```

### ëª¨ë¸ì´ ì—†ë‹¤ëŠ” ì—ëŸ¬
```bash
# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
ollama list

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama3.2
```

### í¬íŠ¸ ì¶©ëŒ
`main.py`ì—ì„œ í¬íŠ¸ ë²ˆí˜¸ ë³€ê²½:
```python
uvicorn.run(app, host="0.0.0.0", port=8001)  # 8000 -> 8001
```

## ê°œë°œ ëª¨ë“œ

```bash
# ìë™ ì¬ì‹œì‘ ëª¨ë“œë¡œ ì‹¤í–‰
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```
